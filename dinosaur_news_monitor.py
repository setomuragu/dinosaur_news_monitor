"""
ê³µë£¡ ë‰´ìŠ¤ ì‹¤ì‹œê°„ ì•Œë¦¼ ì„œë¹„ìŠ¤ v5.0 - í‚¤ì›Œë“œ ìš°ì„  ë¶„ë¥˜ ê°œì„ 

ì£¼ìš” ê°œì„ ì‚¬í•­:
- í‚¤ì›Œë“œ ìš°ì„  ë¶„ë¥˜ -> ì• ë§¤í•œ ê²½ìš°ë§Œ API í˜¸ì¶œ
- API ë¹„ìš© ì ˆì•½ (ì˜ˆìƒ 70-80% ì ˆì•½)
- 3ë‹¨ê³„ ì‹ ë¢°ë„ ê¸°ë°˜ ë¶„ë¥˜
- ì‹¤ì‹œê°„ ì ˆì•½ í†µê³„ 
"""

import asyncio
import feedparser
import json
import hashlib
import pickle
import logging
import os
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import aiohttp
from bs4 import BeautifulSoup
from telegram import Bot
from telegram.error import TelegramError
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import pytz
import anthropic

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

class ImprovedDinosaurClassifier:
    """í‚¤ì›Œë“œ ìš°ì„  + API ë³´ì™„ ë¶„ë¥˜ê¸°"""

    def __init__(self):
        # Claude í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.claude_client = None
        claude_api_key = os.getenv('ANTHROPIC_API_KEY') or os.getenv('CLAUDE_API_KEY')
        if claude_api_key:
            try:
                self.claude_client = anthropic.Anthropic(api_key=claude_api_key)
                logger.info("Claude API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"Claude ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        # í™•ì‹¤í•œ í¬í•¨ í‚¤ì›Œë“œ (ë†’ì€ ì‹ ë¢°ë„)
        self.strong_include_keywords = [
            'dinosaur', 'dinosaurs', 'fossil', 'fossils', 'paleontology', 'paleontologist',
            'cretaceous', 'jurassic', 'triassic', 'mesozoic', 'extinct reptile',
            'tyrannosaur', 'sauropod', 'theropod', 'ceratopsian', 'hadrosau',
            'Tyrannosaurus', 'Triceratops', 'Stegosaurus', 'Velociraptor',
            'pterosaur', 'archaeopteryx', 'prehistoric reptile', 'paleocene',
            'ê³µë£¡', 'í™”ì„', 'ê³ ìƒë¬¼í•™', 'ë°±ì•…ê¸°', 'ì¥ë¼ê¸°', 'ì¤‘ìƒëŒ€',
            'brachiosaurus', 'allosaurus', 'spinosaurus', 'iguanodon', 'RFK'
        ]

        # í™•ì‹¤í•œ ì œì™¸ í‚¤ì›Œë“œ (ë†’ì€ ì‹ ë¢°ë„)  
        self.strong_exclude_keywords = [
            'cancer treatment', 'human disease', 'COVID', 'vaccine', 'politics',
            'rocket launch', 'space mission', 'satellite', 'mars rover',
            'smartphone', 'AI technology', 'clinical trial', 'patient study',
            'stock market', 'economic', 'business', 'cryptocurrency',
            'medical diagnosis', 'pharmaceutical', 'hospital', 'therapy',
            'human skull', 'human remains', 'modern medicine', 'brain cancer',
            'black hole', 'neutrino', 'quantum', 'nanotechnology'
        ]

        # ì¤‘ê°„ ê°•ë„ í‚¤ì›Œë“œë“¤
        self.medium_include_keywords = [
            'ancient', 'prehistoric', 'extinct', 'evolution', 'specimen',
            'excavation', 'discovery', 'bone', 'skeleton', 'species',
            'vertebrate', 'reptile', 'cretaceous period', 'jurassic period'
        ]

        self.medium_exclude_keywords = [
            'modern animal', 'human archaeology', 'medical research', 
            'technology', 'engineering', 'astronomy', 'physics',
            'plant biology', 'marine biology', 'cell biology'
        ]

        # Claude ë¶„ë¥˜ìš© í”„ë¡¬í”„íŠ¸
        self.classification_prompt = """
You are a dinosaur and paleontology expert classifier.
Judge whether the following text is related to dinosaurs, fossils, and paleontology:

- RELEVANT: "RELEVANT"
- IRRELEVANT: "IRRELEVANT"

Relevant: Dinosaurs, fossils, paleontology, Mesozoic Era, extinction, evolution, etc
Not Relevant: Modern medicine, space exploration, politics, agriculture, technology, etc

Just one word: RELEVANT or IRRELEVANT
"""

    def calculate_keyword_confidence(self, title: str, summary: str) -> Dict[str, float]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        combined_text = (title + ' ' + summary).lower()

        scores = {
            'strong_include': 0,
            'strong_exclude': 0, 
            'medium_include': 0,
            'medium_exclude': 0
        }

        # ê°•ë ¥í•œ í¬í•¨ í‚¤ì›Œë“œ ì²´í¬
        for keyword in self.strong_include_keywords:
            if keyword.lower() in combined_text:
                scores['strong_include'] += 3

        # ê°•ë ¥í•œ ì œì™¸ í‚¤ì›Œë“œ ì²´í¬  
        for keyword in self.strong_exclude_keywords:
            if keyword.lower() in combined_text:
                scores['strong_exclude'] += 3

        # ì¤‘ê°„ í‚¤ì›Œë“œë“¤
        for keyword in self.medium_include_keywords:
            if keyword.lower() in combined_text:
                scores['medium_include'] += 1

        for keyword in self.medium_exclude_keywords:
            if keyword.lower() in combined_text:
                scores['medium_exclude'] += 1

        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        include_score = scores['strong_include'] + scores['medium_include'] * 0.5
        exclude_score = scores['strong_exclude'] + scores['medium_exclude'] * 0.5

        final_score = include_score - exclude_score

        # ì‹ ë¢°ë„ ê³„ì‚° (0.0 ~ 1.0)
        if final_score >= 3:
            confidence = 0.95  # ë§¤ìš° í™•ì‹¤í•¨
        elif final_score >= 2:
            confidence = 0.85  # í™•ì‹¤í•¨  
        elif final_score >= 1:
            confidence = 0.75  # ì–´ëŠì •ë„ í™•ì‹¤
        elif final_score <= -3:
            confidence = 0.95  # ë§¤ìš° í™•ì‹¤íˆ ì œì™¸
        elif final_score <= -2:
            confidence = 0.85  # í™•ì‹¤íˆ ì œì™¸
        elif final_score <= -1:
            confidence = 0.75  # ì–´ëŠì •ë„ í™•ì‹¤íˆ ì œì™¸
        else:
            confidence = 0.3   # ì• ë§¤í•¨ - API í•„ìš”

        return {
            'score': final_score,
            'confidence': confidence,
            'include_score': include_score,
            'exclude_score': exclude_score,
            'decision': final_score > 0
        }

    async def classify_with_keywords_first(self, title: str, summary: str) -> Dict[str, any]:
        """í‚¤ì›Œë“œ ìš°ì„  + API ë³´ì™„ ë¶„ë¥˜"""

        # 1ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        keyword_result = self.calculate_keyword_confidence(title, summary)

        # 2ë‹¨ê³„: ì‹ ë¢°ë„ì— ë”°ë¥¸ ê²°ì •
        if keyword_result['confidence'] >= 0.8:
            # í‚¤ì›Œë“œë§Œìœ¼ë¡œ í™•ì‹¤í•œ ë¶„ë¥˜ ê°€ëŠ¥ - API ìƒëµ
            logger.info(f"ğŸ” í‚¤ì›Œë“œ ë¶„ë¥˜ í™•ì • (ì‹ ë¢°ë„: {keyword_result['confidence']:.2f})")
            return {
                'decision': keyword_result['decision'],
                'confidence': keyword_result['confidence'],
                'method': 'keyword_only',
                'api_used': False,
                'keyword_score': keyword_result['score']
            }

        elif keyword_result['confidence'] <= 0.4:
            # ì• ë§¤í•œ ê²½ìš° - API í˜¸ì¶œ
            logger.info(f"â“ í‚¤ì›Œë“œ ë¶„ë¥˜ ì• ë§¤í•¨ (ì‹ ë¢°ë„: {keyword_result['confidence']:.2f}) - API í˜¸ì¶œ")

            api_result = await self.classify_with_claude(title, summary)

            # APIì™€ í‚¤ì›Œë“œ ê²°ê³¼ ì¢…í•©
            if api_result is not None:
                final_confidence = max(keyword_result['confidence'], 0.7)
                return {
                    'decision': api_result,
                    'confidence': final_confidence,
                    'method': 'hybrid_api_used',
                    'api_used': True,
                    'keyword_score': keyword_result['score'],
                    'api_decision': api_result
                }
            else:
                # API ì‹¤íŒ¨ì‹œ í‚¤ì›Œë“œ ê²°ê³¼ ì‚¬ìš©
                return {
                    'decision': keyword_result['decision'],
                    'confidence': keyword_result['confidence'],
                    'method': 'keyword_fallback',
                    'api_used': False,
                    'keyword_score': keyword_result['score']
                }
        else:
            # ì¤‘ê°„ ì‹ ë¢°ë„ - ë³´ìˆ˜ì  ì ‘ê·¼ (ê±°ë¶€ ìš°ì„ )
            conservative_decision = keyword_result['score'] > 1  # ë” ì—„ê²©í•œ ê¸°ì¤€
            return {
                'decision': conservative_decision,
                'confidence': 0.6,
                'method': 'conservative_keyword',
                'api_used': False,
                'keyword_score': keyword_result['score']
            }

    async def classify_with_claude(self, title: str, summary: str) -> Optional[bool]:
        """Claude API ë¶„ë¥˜"""
        if not self.claude_client:
            return None

        try:
            combined_text = f"ì œëª©: {title}\në‚´ìš©: {summary}"
            response = await asyncio.to_thread(
                self.claude_client.messages.create,
                model="claude-sonnet-4-20250514",
                max_tokens=10,
                temperature=0.1,
                system=self.classification_prompt,
                messages=[{"role": "user", "content": combined_text}]
            )

            classification = response.content[0].text.strip().upper()
            if classification == "RELEVANT":
                return True
            elif classification == "IRRELEVANT":
                return False
            else:
                logger.warning(f"âš ï¸ Claude ë¶„ë¥˜ ëª¨í˜¸: {classification}")
                return None

        except Exception as e:
            logger.error(f"Claude ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return None

class OptimizedDinosaurNewsMonitor:
    """í‚¤ì›Œë“œ ìš°ì„  ë¶„ë¥˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ìµœì í™”ëœ ê³µë£¡ ë‰´ìŠ¤ ëª¨ë‹ˆí„°"""

    def __init__(self, bot_token: str, channel_id: str):
        self.bot = Bot(token=bot_token)
        self.channel_id = channel_id
        self.scheduler = AsyncIOScheduler(timezone=pytz.timezone('Asia/Seoul'))
        self.state_file = 'dinosaur_news_state.json'
        self.sent_items = self.load_state()

        # ê°œì„ ëœ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        self.classifier = ImprovedDinosaurClassifier()

        # API ì‚¬ìš© í†µê³„
        self.api_stats = {
            'total_classifications': 0,
            'api_calls': 0,
            'keyword_only': 0,
            'cost_saved': 0
        }

        # RSS í”¼ë“œ ëª©ë¡ 
        self.rss_feeds = {
            'Nature Paleontology': 'https://www.nature.com/subjects/palaeontology.rss',
            'PeerJ Paleontology Highly rated': 'https://peerj.com/articles/index.atom?section=paleontology-evolutionary-science&rating=5',
            'Live Science': 'https://www.livescience.com/feeds/all',
            'Science Daily Fossils': 'https://www.sciencedaily.com/rss/fossils_ruins.xml',
            'Universe Today': 'https://www.universetoday.com/feed/',
            'Nature Palaeontology': 'https://www.nature.com/subjects/palaeontology.rss',
            'Papers in Palaeontology': 'https://onlinelibrary.wiley.com/feed/20562802/most-recent',
            'dinosaur paleontology': 'https://pubmed.ncbi.nlm.nih.gov/rss/search/12MSb85m6hH8GiP-RH4NXuZ7B20URJZ2xSdh0nILvbL9n-iQ64/?limit=15&utm_campaign=pubmed-2&fc=20250904041631',
            'fossil vertebrate paleontology': 'https://pubmed.ncbi.nlm.nih.gov/rss/search/1DeUIcPgNLDFQS_E3SIgJGohhLIM1emALmYrOGJPdeuo0Xv9VR/?limit=15&utm_campaign=pubmed-2&fc=20250904041812',
            'r/science': 'https://www.reddit.com/r/science/hot/.rss',
            'SciTechDaily': 'https://scitechdaily.com/feed/',
            'Nature News': 'https://www.nature.com/nature.rss',
            'Science Magazine': 'https://www.science.org/rss/news_current.xml',
            'New Scientist': 'https://www.newscientist.com/feed/home/',
            'Scientific American': 'http://rss.sciam.com/basic-science',
            'Phys.org': 'https://phys.org/rss-feed/'
        }

        # HTTP ì„¸ì…˜
        self.session = None

        # í‚¤ì›Œë“œ ë²ˆì—­ ì‚¬ì „ (ë°±ì—…ìš©)
        self.translation_patterns = {
            # ê³µë£¡ ì´ë¦„
            r'\bTyrannosaurus\b': 'í‹°ë¼ë…¸ì‚¬ìš°ë£¨ìŠ¤',
            r'\bTriceratops\b': 'íŠ¸ë¦¬ì¼€ë¼í†±ìŠ¤',
            r'\bStegosaurus\b': 'ìŠ¤í…Œê³ ì‚¬ìš°ë£¨ìŠ¤',
            r'\bVelociraptor\b': 'ë²¨ë¡œí‚¤ëí† ë¥´',
            r'\bBrachiosaurus\b': 'ë¸Œë¼í‚¤ì˜¤ì‚¬ìš°ë£¨ìŠ¤',
            # ì‹œëŒ€ëª…
            r'\bCretaceous\b': 'ë°±ì•…ê¸°',
            r'\bJurassic\b': 'ì¥ë¼ê¸°',
            r'\bTriassic\b': 'íŠ¸ë¼ì´ì•„ìŠ¤ê¸°',
            r'\bMesozoic\b': 'ì¤‘ìƒëŒ€',
            # ê³ ìƒë¬¼í•™ ìš©ì–´
            r'\bfossil(?:s)?\b': 'í™”ì„',
            r'\bdinosaur(?:s)?\b': 'ê³µë£¡',
            r'\bpaleontology\b': 'ê³ ìƒë¬¼í•™',
            r'\bpaleontologist(?:s)?\b': 'ê³ ìƒë¬¼í•™ì',
            r'\bextinct(?:ion)?\b': 'ë©¸ì¢…',
            r'\bevolution(?:ary)?\b': 'ì§„í™”',
            r'\bspecies\b': 'ì¢…',
            r'\bskeleton\b': 'ê³¨ê²©',
            r'\bbone(?:s)?\b': 'ë¼ˆ',
            # ë™ì‚¬
            r'\bdiscover(?:ed|y)?\b': 'ë°œê²¬',
            r'\bfound\b': 'ë°œê²¬ëœ',
            r'\bannounce(?:d)?\b': 'ë°œí‘œ',
            r'\breveal(?:ed)?\b': 'ê³µê°œ',
            r'\bstudy\b': 'ì—°êµ¬'
        }

    async def is_dinosaur_news_optimized(self, title: str, summary: str) -> bool:
        """ìµœì í™”ëœ ê³µë£¡ ë‰´ìŠ¤ ë¶„ë¥˜"""

        result = await self.classifier.classify_with_keywords_first(title, summary)

        # í†µê³„ ì—…ë°ì´íŠ¸
        self.api_stats['total_classifications'] += 1
        if result['api_used']:
            self.api_stats['api_calls'] += 1
        else:
            self.api_stats['keyword_only'] += 1
            self.api_stats['cost_saved'] += 0.001  # ì˜ˆìƒ ì ˆì•½ ë¹„ìš©

        # ë¡œê¹…
        method_emoji = {
            'keyword_only': 'âš¡',
            'hybrid_api_used': 'ğŸ”„', 
            'conservative_keyword': 'ğŸ›¡ï¸',
            'keyword_fallback': 'ğŸ”™'
        }

        emoji = method_emoji.get(result['method'], 'â“')
        logger.info(f"{emoji} {result['method']}: {result['decision']} (ì‹ ë¢°ë„: {result['confidence']:.2f})")

        return result['decision']

    def print_api_savings_stats(self):
        """API ì ˆì•½ í†µê³„ ì¶œë ¥"""
        if self.api_stats['total_classifications'] > 0:
            keyword_ratio = (self.api_stats['keyword_only'] / self.api_stats['total_classifications']) * 100
            logger.info(f"ğŸ’° API ì ˆì•½ í†µê³„:")
            logger.info(f"   ì „ì²´ ë¶„ë¥˜: {self.api_stats['total_classifications']}íšŒ")
            logger.info(f"   í‚¤ì›Œë“œë§Œ ì‚¬ìš©: {self.api_stats['keyword_only']}íšŒ ({keyword_ratio:.1f}%)")
            logger.info(f"   API í˜¸ì¶œ: {self.api_stats['api_calls']}íšŒ")
            logger.info(f"   ì˜ˆìƒ ì ˆì•½ ë¹„ìš©: ${self.api_stats['cost_saved']:.3f}")

    async def init_session(self):
        """HTTP ì„¸ì…˜ ì´ˆê¸°í™”"""
        if self.session is None:
            self.session = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30),
                headers={'User-Agent': 'DinosaurNewsBot/5.0'}
            )

    async def close_session(self):
        """HTTP ì„¸ì…˜ ì¢…ë£Œ"""
        if self.session:
            await self.session.close()

    def load_state(self) -> set:
        """ì´ì „ì— ì „ì†¡ëœ ë‰´ìŠ¤ í•­ëª©ë“¤ì„ ë¡œë“œ"""
        try:
            if os.path.exists(self.state_file):
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(data.get('sent_items', []))
        except Exception as e:
            logger.error(f"ìƒíƒœ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return set()

    def save_state(self):
        """í˜„ì¬ ìƒíƒœë¥¼ íŒŒì¼ì— ì €ì¥"""
        try:
            state_data = {
                'sent_items': list(self.sent_items),
                'last_update': datetime.now().isoformat()
            }
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ìƒíƒœ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    def generate_item_id(self, title: str, link: str) -> str:
        """ë‰´ìŠ¤ í•­ëª©ì˜ ê³ ìœ  ID ìƒì„±"""
        return hashlib.md5(f"{title}{link}".encode('utf-8')).hexdigest()

    def is_new_item(self, title: str, link: str) -> bool:
        """ìƒˆë¡œìš´ ë‰´ìŠ¤ í•­ëª©ì¸ì§€ í™•ì¸"""
        item_id = self.generate_item_id(title, link)
        if item_id not in self.sent_items:
            self.sent_items.add(item_id)
            return True
        return False

    async def translate_with_claude(self, text: str) -> str:
        """Claude APIë¥¼ ì‚¬ìš©í•œ ë²ˆì—­"""
        if not self.classifier.claude_client or not text:
            return ""

        try:
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë¹„ìš© ì ˆì•½)
            text_to_translate = text[:200] if len(text) > 200 else text

            response = await asyncio.to_thread(
                self.classifier.claude_client.messages.create,
                model="claude-3-5-haiku-20241022",
                max_tokens=300,
                system="You are a dinosaur and paleontology expert translator. Translate English text into natural and accurate Korean. Translate academic terms precisely but make them easy to read. Provide only the translation.",
                messages=[
                    {"role": "user", "content": f"Please translate the following English text into Korean.: {text_to_translate}"}
                ]
            )

            translated = response.content[0].text.strip()

            # ë²ˆì—­ ê²°ê³¼ ê²€ì¦
            if translated and len(translated) > 3 and "ë²ˆì—­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in translated:
                logger.info(f"Claude ë²ˆì—­ ì„±ê³µ: {text[:30]}... â†’ {translated[:30]}...")
                return translated
            else:
                logger.warning(f"Claude ë²ˆì—­ ê²°ê³¼ ë¶€ì ì ˆ: {translated}")
                return ""

        except Exception as e:
            logger.warning(f"Claude ë²ˆì—­ ì‹¤íŒ¨: {e}")
            return ""

    def fallback_translate(self, text: str) -> str:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ë°±ì—… ë²ˆì—­"""
        if not text:
            return ""

        translated = text

        # íŒ¨í„´ë³„ ë²ˆì—­ ì ìš©
        for pattern, replacement in self.translation_patterns.items():
            translated = re.sub(pattern, replacement, translated, flags=re.IGNORECASE)

        return translated

    async def enhanced_translate(self, text: str) -> str:
        """Claude API ìš°ì„  + í‚¤ì›Œë“œ ë°±ì—… ë²ˆì—­"""
        if not text:
            return ""

        # 1. Claude API ë²ˆì—­ ì‹œë„
        if self.classifier.claude_client:
            claude_result = await self.translate_with_claude(text)
            if claude_result:
                return claude_result

        # 2. Claude ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ë²ˆì—­ìœ¼ë¡œ ë°±ì—…
        logger.info("Claude ë²ˆì—­ ì‹¤íŒ¨, í‚¤ì›Œë“œ ë²ˆì—­ ì‚¬ìš©")
        return self.fallback_translate(text)

    async def fetch_rss_feed(self, feed_name: str, feed_url: str) -> List[Dict]:
        """RSS í”¼ë“œë¥¼ ê°€ì ¸ì™€ì„œ íŒŒì‹±"""
        try:
            await self.init_session()
            async with self.session.get(feed_url) as response:
                if response.status == 200:
                    content = await response.text()
                    feed = feedparser.parse(content)

                    if feed.bozo:
                        logger.warning(f"{feed_name} í”¼ë“œ íŒŒì‹± ê²½ê³ : {feed.bozo_exception}")

                    new_entries = []
                    for entry in feed.entries[:10]:
                        try:
                            title = entry.title
                            link = entry.link
                            summary = entry.get('summary', entry.get('description', ''))

                            # ë°œí–‰ ë‚ ì§œ í™•ì¸
                            pub_date = None
                            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                                pub_date = datetime(*entry.published_parsed[:6])

                            # 24ì‹œê°„ ì´ë‚´ì˜ ìƒˆ í•­ëª©ë§Œ
                            if pub_date and datetime.now() - pub_date > timedelta(days=1):
                                continue

                            # ğŸ”¥ ê°œì„ ëœ ë¶„ë¥˜ ì‚¬ìš©
                            if not await self.is_dinosaur_news_optimized(title, summary):
                                continue

                            if self.is_new_item(title, link):
                                # Claude ë²ˆì—­ ìˆ˜í–‰
                                title_ko = await self.enhanced_translate(title)
                                summary_ko = await self.enhanced_translate(summary) if summary else ""

                                new_entries.append({
                                    'title': title,
                                    'title_ko': title_ko,
                                    'link': link,
                                    'summary': summary,
                                    'summary_ko': summary_ko,
                                    'published': pub_date,
                                    'source': feed_name
                                })

                                # ë²ˆì—­ ì§€ì—° (API ì œí•œ ê³ ë ¤)
                                await asyncio.sleep(1)

                        except Exception as e:
                            logger.error(f"í•­ëª© íŒŒì‹± ì˜¤ë¥˜ ({feed_name}): {e}")
                            continue

                    return new_entries
                else:
                    logger.error(f"{feed_name} í”¼ë“œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: HTTP {response.status}")

        except Exception as e:
            logger.error(f"{feed_name} RSS í”¼ë“œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

        return []

    def escape_markdown_v2(self, text: str) -> str:
        """í…”ë ˆê·¸ë¨ MarkdownV2ìš© íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„"""
        if not text:
            return ""

        # ëª¨ë“  íŠ¹ìˆ˜ë¬¸ìë¥¼ í•œ ë²ˆì— ì´ìŠ¤ì¼€ì´í”„
        return re.sub(r'([_*\[\]()~`>#+=|{}.!-])', r'\\\1', text)

    def format_bilingual_message(self, item: Dict) -> str:
        """ì˜ì–´/í•œêµ­ì–´ ë³‘ê¸° í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í¬ë§·íŒ…"""
        en_title = self.escape_markdown_v2(item['title'])
        en_summary = ""
        if item.get('summary'):
            summary_text = item['summary']
            if len(summary_text) > 150:
                summary_text = summary_text[:150] + "..."
            en_summary = "\n\n" + self.escape_markdown_v2(summary_text)

        ko_title = self.escape_markdown_v2(item.get('title_ko', item['title']))
        ko_summary = ""
        if item.get('summary_ko'):
            summary_ko_text = item['summary_ko']
            if len(summary_ko_text) > 150:
                summary_ko_text = summary_ko_text[:150] + "..."
            ko_summary = "\n\n" + self.escape_markdown_v2(summary_ko_text)

        source = item['source']
        link = item['link']

        source_info = {
            'Nature Paleontology': {'emoji': 'ğŸ”¬', 'ko_name': 'Nature ê³ ìƒë¬¼í•™'},
            'PeerJ Paleontology': {'emoji': 'ğŸ“„', 'ko_name': 'PeerJ ê³ ìƒë¬¼í•™'},
            'Live Science': {'emoji': 'ğŸ§¬', 'ko_name': 'Live Science'},
            'Science Daily Fossils': {'emoji': 'ğŸ¦´', 'ko_name': 'Science Daily í™”ì„'},
            'Universe Today': {'emoji': 'ğŸŒŒ', 'ko_name': 'Universe Today'}
        }

        emoji = source_info.get(source, {}).get('emoji', 'ğŸ¦•')
        ko_source = source_info.get(source, {}).get('ko_name', source)

        separator = "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        hashtag_source = source.replace(' ', '').replace('PeerJ', 'PeerJ')
        hash_symbol = "\\#"  # ì´ìŠ¤ì¼€ì´í”„ ìœ ì§€

        message = f"""{emoji} *{self.escape_markdown_v2(source)}*\n\n*{en_title}*{en_summary}\n\n[Read more]({link})\n\n{separator}\n\n{emoji} *{self.escape_markdown_v2(ko_source)}*\n\n*{ko_title}*{ko_summary}\n\n[ìì„¸íˆ ë³´ê¸°]({link})\n\n{hash_symbol}{hashtag_source} {hash_symbol}ê³µë£¡ë‰´ìŠ¤ {hash_symbol}DinosaurNews"""

        return message

    async def send_telegram_message(self, message: str) -> bool:
        """í…”ë ˆê·¸ë¨ ì±„ë„ì— ë©”ì‹œì§€ ì „ì†¡"""
        try:
            await self.bot.send_message(
                chat_id=self.channel_id,
                text=message,
                parse_mode='MarkdownV2',
                disable_web_page_preview=False
            )
            return True

        except TelegramError as e:
            logger.error(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì˜¤ë¥˜: {e}")

            # MarkdownV2 íŒŒì‹± ì˜¤ë¥˜ ì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„
            if "parse entities" in str(e).lower():
                try:
                    # ë§ˆí¬ë‹¤ìš´ ì œê±°í•œ í”Œë ˆì¸ í…ìŠ¤íŠ¸ ë²„ì „
                    plain_message = re.sub(r'[*_\\#\[\]]', '', message)
                    plain_message = plain_message.replace('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”', '----------------')

                    await self.bot.send_message(
                        chat_id=self.channel_id,
                        text=plain_message,
                        disable_web_page_preview=False
                    )
                    logger.info("ë§ˆí¬ë‹¤ìš´ ì˜¤ë¥˜ë¡œ ì¸í•´ í”Œë ˆì¸ í…ìŠ¤íŠ¸ë¡œ ì „ì†¡ë¨")
                    return True

                except Exception as e2:
                    logger.error(f"í”Œë ˆì¸ í…ìŠ¤íŠ¸ ì „ì†¡ë„ ì‹¤íŒ¨: {e2}")
                    return False

        except Exception as e:
            logger.error(f"ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False

    async def check_all_sources(self):
        """ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ìƒˆ ë‰´ìŠ¤ í™•ì¸"""
        logger.info("ğŸ¦• ê³µë£¡ ë‰´ìŠ¤ ì†ŒìŠ¤ í™•ì¸ ì‹œì‘... (í‚¤ì›Œë“œ ìš°ì„  ë¶„ë¥˜)")
        all_items = []

        # RSS í”¼ë“œ í™•ì¸
        for feed_name, feed_url in self.rss_feeds.items():
            items = await self.fetch_rss_feed(feed_name, feed_url)
            all_items.extend(items)
            await asyncio.sleep(2)  # Claude API í˜¸ì¶œ ê°„ê²© ê³ ë ¤

        # ìƒˆ í•­ëª©ë“¤ì„ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì „ì†¡
        sent_count = 0
        for item in all_items:
            message = self.format_bilingual_message(item)
            if await self.send_telegram_message(message):
                sent_count += 1
                logger.info(f"ì „ì†¡ ì™„ë£Œ: {item['title'][:50]}... â†’ {item.get('title_ko', 'N/A')[:30]}...")
                await asyncio.sleep(5)  # ì „ì†¡ ê°„ê²©

        # ìƒíƒœ ì €ì¥
        self.save_state()

        # API ì ˆì•½ í†µê³„ ì¶œë ¥
        self.print_api_savings_stats()

        logger.info(f"ê³µë£¡ ë‰´ìŠ¤ í™•ì¸ ì™„ë£Œ. {sent_count}ê°œ ìƒˆ í•­ëª© ì „ì†¡")

    async def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        logger.info("ğŸ¦• ê³µë£¡ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì‹œì‘ (í‚¤ì›Œë“œ ìš°ì„  ë¶„ë¥˜, API ì ˆì•½)")

        # Claude ë²ˆì—­ í…ŒìŠ¤íŠ¸
        if self.classifier.claude_client:
            test_translation = await self.enhanced_translate("Scientists discover new dinosaur species")
            logger.info(f"Claude ë²ˆì—­ í…ŒìŠ¤íŠ¸: 'Scientists discover new dinosaur species' â†’ '{test_translation}'")
        else:
            logger.info("Claude API ë¯¸ì‚¬ìš©, í‚¤ì›Œë“œ ë²ˆì—­ë§Œ ì‚¬ìš©")

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • - 30ë¶„ë§ˆë‹¤ ì‹¤í–‰
        self.scheduler.add_job(
            self.check_all_sources,
            'interval',
            minutes=30,
            id='news_check',
            max_instances=1
        )

        # ì‹œì‘ ì‹œ í•œ ë²ˆ ì‹¤í–‰
        await self.check_all_sources()

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
        self.scheduler.start()

        try:
            while True:
                await asyncio.sleep(60)
        except KeyboardInterrupt:
            logger.info("ëª¨ë‹ˆí„°ë§ ì¤‘ì§€...")
            self.scheduler.shutdown()
            await self.close_session()

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
    channel_id = os.getenv('TELEGRAM_CHANNEL_ID')

    if not bot_token or not channel_id:
        print("í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤:")
        print("TELEGRAM_BOT_TOKEN=your_bot_token")
        print("TELEGRAM_CHANNEL_ID=your_channel_id")
        print("CLAUDE_API_KEY=your_claude_api_key # ì„ íƒì‚¬í•­")
        print("")
        print(".env íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
        return

    monitor = OptimizedDinosaurNewsMonitor(bot_token, channel_id)
    await monitor.start_monitoring()

if __name__ == "__main__":
    asyncio.run(main())
